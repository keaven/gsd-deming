# Group sequential design boundary with weighted logrank test {#wlr-boundary}

```{r, include=FALSE}
library(dplyr)
library(gsDesign)
library(gsdmvn)
library(mvtnorm)
```

## Group sequential design boundary calculation strategy

In the last chapter, we pre-specified boundary derived from `gsDesign`.
The Type I error may be inflated because the information fraction is different for different WLR.

In this chapter we calculate boundary based on the error spending approach following @gordon1983discrete.

The spending function has been implemented in `gsDesign`.

- `gsDesign::sfLDOF()` (O'Brien-Fleming bound approximation) or other functions starting with `sf` in `gsDesign`
- The boundary family approach. @pocock1977group, @o1979multiple, @wang1987approximately

There are other ways to derive boundary but will not be covered:

- Conditional power. @lachin2005review

## Types of error probability

There are 6 different type of error probability that have been implemented in `gsdmvn`.
In this training material, we focus on `test.type = 4`.

- `test.type` argument in `gsDesign`
- Upper bound:
  - $\alpha_k(0) = \text{Pr}(\cap_{i=1}^{i=k-1} a_i < Z_i < b_i, Z_k > b_k \mid H_0)$
  - $\alpha_k^{+}(0) = \text{Pr}(\cap_{i=1}^{i=k-1} a_i < Z_i < b_i, Z_k > b_k \mid H_0)$ (ignore lower bound)

- Lower bound:
  - $\beta_k(0) = \text{Pr}(\cap_{i=1}^{i=k-1} a_i < Z_i < b_i, Z_k < a_k \mid H_0)$ (under null)
  - $\beta_k(\delta) = \text{Pr}(\cap_{i=1}^{i=k-1} a_i < Z_i < b_i, Z_k < a_k \mid H_1)$ (under alternative)

   `test.type`      Upper bound         Lower bound
  ------------- ------------------- -------------------
        1        $\alpha_k^{+}(0)$         None
        2           $\alpha(0)$        $\beta_k(0)$
        3          $\alpha_k(0)$     $\beta_k(\delta)$
        4        $\alpha_k^{+}(0)$   $\beta_k(\delta)$
        5           $\alpha(0)$        $\beta_k(0)$
        6         $\alpha^{+}(0)$      $\beta_k(0)$

- `test.type = 1, 2, 5, 6`: sample size boundaries can be computed in a single step.
- `test.type = 3` and `test.type = 4`: sample size and boundaries are set simultaneously using an iterative algorithm.
- This section and last section focus on `test.type = 4`.

## Information fraction

Under the same design assumption,
information fraction is different from different weight parameters in WLR.

We continue use the same example scenario in the last chapter.

```{r, include=FALSE}
enrollRates <- tibble::tibble(Stratum = "All", duration = 12, rate = 500 / 12)

failRates <- tibble::tibble(
  Stratum = "All",
  duration = c(4, 100),
  failRate = log(2) / 15, # Median survival is 15 months
  hr = c(1, .6),
  dropoutRate = 0.001
)
```

```{r, include=FALSE}
# Randomization ratio is 1:1
ratio <- 1

# Type I error (one-sided)
alpha <- 0.025

# Power (1 - beta)
beta <- 0.2
power <- 1 - beta

# Interim analysis time
analysisTimes <- c(12, 24, 36)
```

```{r, echo = FALSE, out.width = "60%"}
knitr::include_graphics("images/g_info.png")
```

## Spending function based on information fraction

The spending function is based on information fraction.
We considered the Lan-DeMets spending function to approximate an O'Brien-Fleming bound @gordon1983discrete. (`gsDesign::sfLDOF()`).

Here, $t$ is information fraction in the formula below.

$$f(t; \alpha)=2-2\Phi\left(\Phi^{-1}\left(\frac{1-\alpha/2}{t^{\rho/2}}\right)\right)$$

### Spending function in `gsDesign`

After the spending function is selected, we can calculate the lower and upper bound of a
group sequential design.

In test type 4, the lower bound is non-binding. So we set lower bound are all `-Inf` when we calculate the probability to cross upper bound.

We first use the alpha spending function to determine upper bound of a group sequential design

- Let $(a_k, b_k), k=1,\dots, K$ denotes the lower and upper bound.

For gsDesign with logrank test,
we considered a equal increments of information fraction at `t = 1:3 / 3` is.

The upper bound and lower bound based on Lan-DeMets spending function
can be calculated using `gsDesign::sfLDOF()`.

- Upper bound:

```{r}
alpha_spend <- gsDesign::sfLDOF(alpha = 0.025, t = 1:3 / 3)$spend
alpha_spend
```

- Lower bound:

```{r}
beta_spend <- gsDesign::sfLDOF(alpha = 0.2, t = 1:3 / 3)$spend
beta_spend
```

We considered different WLR tests with weight functions: $FH(0, 0)$, $FH(0.5, 0.5)$, $FH(0, 0.5)$, $FH(0, 1)$

```{r}
weight_fun <- list(
  function(x, arm0, arm1) {
    gsdmvn::wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0)
  },
  function(x, arm0, arm1) {
    gsdmvn::wlr_weight_fh(x, arm0, arm1, rho = 0.5, gamma = 0.5)
  },
  function(x, arm0, arm1) {
    gsdmvn::wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0.5)
  },
  function(x, arm0, arm1) {
    gsdmvn::wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 1)
  }
)

# Weight name
weight_name <- data.frame(rho = c(0, 0.5, 0, 0), gamma = c(0, 0.5, 0.5, 1))
weight_name <- with(weight_name, paste0("rho = ", rho, "; gamma = ", gamma))
```

For test type 4, the alpha and beta is defined as below.

- $\alpha_k^{+}(0) = \text{Pr}(\cap_{i=1}^{i=k-1} a_i < Z_i < b_i, Z_k > b_k \mid H_0)$ (ignore lower bound)
  - $\alpha_k^{+}(0)$ is calculated under the null. It is the same for different sample size.
- $\beta_k(\delta) =  \text{Pr}(\cap_{i=1}^{i=k-1} a_i < Z_i < b_i, Z_k < a_k \mid H_1)$ (under alternative)
  - $\beta_k(\delta)$ is calculated under the alternative. It depends on the sample size.
  - Iteration is required to find proper sample size and boundary.

The table below provide the cumulative alpha and beta at different analysis time for each WLR test.

we draw the Alpha spending ($\alpha=0.025$) function
based on information fraction at 12, 24 and 36 months

```{r, echo = FALSE, out.width = "60%"}
knitr::include_graphics("images/g_alpha.png")
```

Similarly, we draw the Beta spending ($\beta=0.2$) function
based on information fraction at 12, 24 and 36 months

```{r, echo = FALSE, out.width = "60%"}
knitr::include_graphics("images/g_beta.png")
```

```{r}
analysisTimes <- c(12, 24, 36)
gs_spend <- lapply(weight_fun, function(weight) {
  tmp <- gsdmvn::gs_info_wlr(
    enrollRates, failRates,
    analysisTimes = analysisTimes,
    weight = weight
  )

  tmp %>% mutate(
    theta = abs(delta) / sqrt(sigma2),
    info = info / max(info),
    info0 = info0 / max(info0),
    alpha = gsDesign::sfLDOF(alpha = 0.025, t = info0)$spend,
    beta = gsDesign::sfLDOF(alpha = 0.20, t = info)$spend
  )
})
```

```{r}
names(gs_spend) <- weight_name
bind_rows(gs_spend, .id = "weight") %>%
  select(weight, Time, alpha, beta) %>%
  mutate_if(is.numeric, round, digits = 3)
```

## Lower and upper bound

Let's calculate the lower and upper bound of the first interim analysis.

- First interim analysis upper bound: $\text{Pr}(Z_1 > b_1 \mid H_0)$

```{r}
-qnorm(gs_spend[[1]]$alpha[1])
```

- First interim analysis lower bound $\text{Pr}(Z_1 < b_1 \mid H_1)$

::: {.rmdnote}
The lower bound is calculated under alternative hypothesis and depends on sample size.
:::

```{r}
n <- 400
mean <- gs_spend[[1]]$theta[1] * sqrt(n)
qnorm(gs_spend[[1]]$beta[1], mean = mean, sd = 1)
```

```{r}
n <- 500
mean <- gs_spend[[1]]$theta[1] * sqrt(n)
qnorm(gs_spend[[1]]$beta[1], mean = mean, sd = 1)
```

The figure below illustrate the lower and upper bound in different sample size

- Larger sample size have a larger lower bound (solid line compared with dashed line)
- Iteration is required to find proper sample size and boundary.

```{r, echo = FALSE, out.width = "60%"}
knitr::include_graphics("images/g_bound.png")
```

## Sample size calculation logrank test based on AHR

- Sample size

```{r}
x <- gsdmvn::gs_design_ahr(
  enrollRates = enrollRates, failRates = failRates,
  ratio = ratio, alpha = alpha, beta = beta,
  upper = gs_spending_bound,
  lower = gs_spending_bound,
  upar = list(sf = gsDesign::sfLDOF, total_spend = alpha),
  lpar = list(sf = gsDesign::sfLDOF, total_spend = beta),
  analysisTimes = analysisTimes
)$bounds %>%
  mutate_if(is.numeric, round, digits = 2)
x
```

- Simulation results based on 10,000 replications.

```{r, echo = FALSE}
load("simulation/simu_gsd_ahr.Rdata")
simu_res %>%
  select(-scenario, -rho, -gamma) %>%
  mutate_if(is.numeric, round, digits = 2)
```

- Type I error

```{r}
gsdmvn::gs_power_npe(
  theta = rep(0, length(analysisTimes)),
  info = x$info0[x$Bound == "Upper"],
  upar = x$Z[x$Bound == "Upper"],
  lpar = rep(-Inf, 3)
)$Probability[1:length(analysisTimes)]
```

- Compared with fixed design

```{r}
gsdmvn::gs_design_ahr(
  enrollRates = enrollRates, failRates = failRates,
  ratio = 1, alpha = 0.025, beta = 0.2,
  upar = -qnorm(0.025),
  lpar = -qnorm(0.025),
  analysisTimes = 36
)$bounds
```

## Sample size calculation logrank test based on WLR $FH(0, 0)$

- Sample size

```{r}
x <- gsdmvn::gs_design_wlr(
  enrollRates = enrollRates, failRates = failRates,
  ratio = ratio, alpha = alpha, beta = beta,
  weight = function(x, arm0, arm1) {
    gsdmvn::wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0)
  },
  upper = gs_spending_bound,
  lower = gs_spending_bound,
  upar = list(sf = gsDesign::sfLDOF, total_spend = alpha),
  lpar = list(sf = gsDesign::sfLDOF, total_spend = beta),
  analysisTimes = analysisTimes
)$bounds %>%
  mutate_if(is.numeric, round, digits = 2)
x
```

- Simulation results based on 10,000 replications.

```{r, echo = FALSE}
load("simulation/simu_gsd_wlr_boundary.Rdata")
simu_res %>%
  subset(rho == 0 & gamma == 0) %>%
  select(-scenario, -rho, -gamma) %>%
  mutate_if(is.numeric, round, digits = 2)
```

- Type I error

```{r}
gsdmvn::gs_power_npe(
  theta = rep(0, length(analysisTimes)),
  info = x$info0[x$Bound == "Upper"],
  upar = x$Z[x$Bound == "Upper"],
  lpar = rep(-Inf, 3)
)$Probability[1:length(analysisTimes)]
```

- Compared with fixed design

```{r}
gsdmvn::gs_design_wlr(
  enrollRates = enrollRates, failRates = failRates,
  weight = function(x, arm0, arm1) {
    gsdmvn::wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0)
  },
  ratio = 1, alpha = 0.025, beta = 0.2,
  upar = -qnorm(0.025),
  lpar = -qnorm(0.025),
  analysisTimes = 36
)$bounds
```

## Sample size calculation $FH(0, 1)$

- Sample size

```{r}
x <- gsdmvn::gs_design_wlr(
  enrollRates = enrollRates, failRates = failRates,
  ratio = ratio, alpha = alpha, beta = beta,
  weight = function(x, arm0, arm1) {
    gsdmvn::wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 1)
  },
  upper = gs_spending_bound,
  lower = gs_spending_bound,
  upar = list(sf = gsDesign::sfLDOF, total_spend = alpha),
  lpar = list(sf = gsDesign::sfLDOF, total_spend = beta),
  analysisTimes = analysisTimes
)$bounds %>%
  mutate_if(is.numeric, round, digits = 2)
x
```

- Simulation results based on 10,000 replications.

```{r, echo = FALSE}
load("simulation/simu_gsd_wlr_boundary.Rdata")
simu_res %>%
  subset(rho == 0 & gamma == 1) %>%
  select(-scenario, -rho, -gamma) %>%
  mutate_if(is.numeric, round, digits = 2)
```

- Type I error

```{r}
gsdmvn::gs_power_npe(
  theta = rep(0, length(analysisTimes)),
  info = x$info0[x$Bound == "Upper"],
  upar = x$Z[x$Bound == "Upper"],
  lpar = rep(-Inf, 3)
)$Probability[1:length(analysisTimes)]
```

- Compared with fixed design

```{r}
gsdmvn::gs_design_wlr(
  enrollRates = enrollRates, failRates = failRates,
  weight = function(x, arm0, arm1) {
    gsdmvn::wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 1)
  },
  ratio = 1, alpha = 0.025, beta = 0.2,
  upar = -qnorm(0.025),
  lpar = -qnorm(0.025),
  analysisTimes = 36
)$bounds
```

## Sample size calculation $FH(0, 0.5)$

- Sample size

```{r}
x <- gsdmvn::gs_design_wlr(
  enrollRates = enrollRates, failRates = failRates,
  ratio = ratio, alpha = alpha, beta = beta,
  weight = function(x, arm0, arm1) {
    gsdmvn::wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0.5)
  },
  upper = gs_spending_bound,
  lower = gs_spending_bound,
  upar = list(sf = gsDesign::sfLDOF, total_spend = alpha),
  lpar = list(sf = gsDesign::sfLDOF, total_spend = beta),
  analysisTimes = analysisTimes
)$bounds %>%
  mutate_if(is.numeric, round, digits = 2)
x
```

- Simulation results based on 10,000 replications.

```{r, echo = FALSE}
load("simulation/simu_gsd_wlr_boundary.Rdata")
simu_res %>%
  subset(rho == 0 & gamma == 0.5) %>%
  select(-scenario, -rho, -gamma) %>%
  mutate_if(is.numeric, round, digits = 2)
```

- Type I error

```{r}
gsdmvn::gs_power_npe(
  theta = rep(0, length(analysisTimes)),
  info = x$info0[x$Bound == "Upper"],
  upar = x$Z[x$Bound == "Upper"],
  lpar = rep(-Inf, 3)
)$Probability[1:length(analysisTimes)]
```

- Compared with fixed design

```{r}
gsdmvn::gs_design_wlr(
  enrollRates = enrollRates, failRates = failRates,
  weight = function(x, arm0, arm1) {
    gsdmvn::wlr_weight_fh(x, arm0, arm1, rho = 0, gamma = 0.5)
  },
  ratio = 1, alpha = 0.025, beta = 0.2,
  upar = -qnorm(0.025),
  lpar = -qnorm(0.025),
  analysisTimes = 36
)$bounds
```

## Sample size calculation $FH(0.5, 0.5)$

- Sample size

```{r}
x <- gsdmvn::gs_design_wlr(
  enrollRates = enrollRates, failRates = failRates,
  ratio = ratio, alpha = alpha, beta = beta,
  weight = function(x, arm0, arm1) {
    gsdmvn::wlr_weight_fh(x, arm0, arm1, rho = 0.5, gamma = 0.5)
  },
  upper = gs_spending_bound,
  lower = gs_spending_bound,
  upar = list(sf = gsDesign::sfLDOF, total_spend = alpha),
  lpar = list(sf = gsDesign::sfLDOF, total_spend = beta),
  analysisTimes = analysisTimes
)$bounds %>%
  mutate_if(is.numeric, round, digits = 2)
x
```

- Simulation results based on 10,000 replications.

```{r}
load("simulation/simu_gsd_wlr_boundary.Rdata")
simu_res %>%
  subset(rho == 0.5 & gamma == 0.5) %>%
  select(-scenario, -rho, -gamma) %>%
  mutate_if(is.numeric, round, digits = 2)
```

- Type I error

```{r}
gsdmvn::gs_power_npe(
  theta = rep(0, length(analysisTimes)),
  info = x$info0[x$Bound == "Upper"],
  upar = x$Z[x$Bound == "Upper"],
  lpar = rep(-Inf, 3)
)$Probability[1:length(analysisTimes)]
```

- Compared with fixed design

```{r}
gsdmvn::gs_design_wlr(
  enrollRates = enrollRates, failRates = failRates,
  weight = function(x, arm0, arm1) {
    gsdmvn::wlr_weight_fh(x, arm0, arm1, rho = 0.5, gamma = 0.5)
  },
  ratio = 1, alpha = 0.025, beta = 0.2,
  upar = -qnorm(0.025),
  lpar = -qnorm(0.025),
  analysisTimes = 36
)$bounds
```
