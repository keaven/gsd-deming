# Generated by pkglite: do not edit by hand
# Use pkglite::unpack() to restore the packages

Package: modestWLRT
File: .Rbuildignore
Format: text
Content:
  ^.*\.Rproj$
  ^\.Rproj\.user$

Package: modestWLRT
File: DESCRIPTION
Format: text
Content:
  Package: modestWLRT
  Type: Package
  Title: Functions for implementing modestly-weighted logrank tests.
  Version: 0.1.0
  Author: Dominic Magirr
  Maintainer: Dominic Magirr <d.magirr@gmail.com>
  Description: Functions for implementing modestly-weighted logrank tests, as described in http://arxiv.org/abs/1807.11097
  License: GPL-3
  LazyData: TRUE
  RoxygenNote: 6.1.1
  Imports: dplyr,
      ggplot2
  Suggests: knitr,
      rmarkdown
  VignetteBuilder: knitr

Package: modestWLRT
File: NAMESPACE
Format: text
Content:
  # Generated by roxygen2: do not edit by hand
  
  export(add_weights)
  export(compare_weights)
  export(delayed_effect_sim)
  export(get_risk_table)
  export(get_zs)
  export(landmark)
  export(ncp_power)
  export(rmst)
  export(three_piece_sim)

Package: modestWLRT
File: README.md
Format: text
Content:
  # modestWLRT
  
  Functions for implementing modestly-weighted logrank tests, as described in
  
  http://arxiv.org/abs/1807.11097
  
  ## Installation
  
  You can use `devtools::install_github()` to get the package from [GitHub](https://github.com/dominicmagirr/modestWLRT):
  
  ```{r eval=FALSE}
  install.packages("devtools")
  library(devtools)
  install_github("dominicmagirr/modestWLRT")
  ```
  
  ## Basic usage
  
  ```{r}
  library(modestWLRT)
  vignette("modestwlrt_vignette")
  ```

Package: modestWLRT
File: R/add_weights.R
Format: text
Content:
  #' Calculate weights for a weighted log-rank test.
  #' 
  #' \code{add_weights} Calculate weights for a weighted log-rank test and add them to the risk table.
  #' @param{risk_table} A risk table produced by the function \code{get_risk_table}.
  #' @param{method} The type of weighted log-rank test.
  #' \code{"fixed_c"} means that the scores \code{c} are fixed at 1 while \code{t < delay}. Thereafter, the weights \code{w} remain fixed.
  #' \code{"fh"} is a Fleming-Harrington test with parameters \code{rho} and \code{gamma}.
  #' \code{"step"} means that the weight \code{w} is fixed at 0 while \code{t < delay}. Thereafter, the weight is fixed at 1. 
  #' @param{delay} Parameter used by the \code{"fixed_c"} and \code{"step"} methods. 
  #' @param{rho} First parameter for the \code{"fh"} method.
  #' @param{gamma} Second parameter for the \code{"fh"} method.
  #' @return A risk table consisting of the original \code{risk_table} with 3 additional columns:
  #' \code{c} The scores in the score test corresponding to events (uncensored observations).
  #' \code{w} The weights for the weighted log-rank test. 
  #' \code{C} The scores in the score test corresponding to censored observations.
  #' @export
  
  
  add_weights = function(risk_table,
                         method = "fixed_c",
                         delay = 6,
                         rho = 0,
                         gamma = 0,
                         plot_weights = FALSE){
    
    
    if (method == "fixed_c"){
      
      
      
      # Kaplan-Meier estimate of survival in the lumped data:
      risk_table$s = exp(cumsum(log(1 - risk_table$d / risk_table$n)))
      risk_table$s_minus = c(1, risk_table$s[-length(risk_table$s)])
      
      if (delay == 0) max_weight = 1
      else { 
        max_weight = 1 / max(risk_table$s[risk_table$t >= delay])
      }
      
      # Modest (delay) weights:
      risk_table$w = pmin(1 / risk_table$s_minus, max_weight) 
      risk_table$c = NA
      risk_table$C = NA
      
      ## w --> C --> c
      
      # use Condition (3) in Leton and Zuluaga:
      
      for (j in 1:length(risk_table$t)){
        
        risk_table$C[j] = -with(risk_table, sum(w[1:j] * d[1:j] / n[1:j]))
        risk_table$c[j] = risk_table$C[j] + risk_table$w[j]
        
      }
      
    }
    else if (method == "fixed_c_orig"){
    
      risk_table$c = 1
      risk_table$w = 1
      risk_table$C = 1
      
      ## c --> w --> C
      
      ## start with c = 1 up to t = delay.
      
      if (any(risk_table$t < delay)) {
        
        # find maximum event time before the end of the delay:
        max_j = max(which(risk_table$t < delay))
        
      }
      else {
        max_j = 0
      }
      
      ## Use Condition (4) in Leton and Zuluaga:
      
      if (max_j > 0){
        
        for (j in 1:max_j){
          
          if (risk_table$n[j] == risk_table$d[j]){
            
            risk_table$w[j] = 0
            
          }
          else if (j == 1){
            
            risk_table$w[j] = risk_table$n[1] / (risk_table$n[1] - risk_table$d[1])
            
          }
          else{ 
            
            risk_table$w[j] = risk_table$w[j-1] * risk_table$n[j] / (risk_table$n[j] - risk_table$d[j])
            
          }
        }
        risk_table$C[1:max_j] = risk_table$c[1:max_j] - risk_table$w[1:max_j]
      }
      ## w --> C --> c
      
      ## now keep w fixed for t > delay
      
      if (max_j < length(risk_table$t)){
        
        risk_table$w[(max_j + 1):length(risk_table$t)] = risk_table$w[max(1,max_j)]
        
        
        # use Condition (3) from Leton and Zuluaga:
        
        for (j in (max_j + 1):length(risk_table$t)){
          
          risk_table$C[j] = -with(risk_table, sum(w[1:j] * d[1:j] / n[1:j]))
          risk_table$c[j] = risk_table$C[j] + risk_table$w[j]
          
        }
        
      }
      
    }
    
    else if (method == "fh"){
      
      
      # Kaplan-Meier estimate of survival in the lumped data:
      risk_table$s = exp(cumsum(log(1 - risk_table$d / risk_table$n)))
      risk_table$s_minus = c(1, risk_table$s[-length(risk_table$s)])
      
      # Fleming-Harrington (rho, gamma) weights:
      risk_table$w = risk_table$s_minus ^ rho * (1 - risk_table$s_minus) ^ gamma
      risk_table$c = NA
      risk_table$C = NA
      
      ## w --> C --> c
      
      # use Condition (3) in Leton and Zuluaga:
      
      for (j in 1:length(risk_table$t)){
        
        risk_table$C[j] = -with(risk_table, sum(w[1:j] * d[1:j] / n[1:j]))
        risk_table$c[j] = risk_table$C[j] + risk_table$w[j]
        
      }
      
      
    }
    
    else if (method == "step"){
      
      
      # weight fixed at zero before delay, 1 after delay:
      
      risk_table$w = ifelse(risk_table$t < delay, 0, 1)
      risk_table$c = NA
      risk_table$C = NA
      
      ## w --> C --> c
      
      # use Condition (3) in Leton and Zuluaga:
      
      for (j in 1:length(risk_table$t)){
        
        risk_table$C[j] = -with(risk_table, sum(w[1:j] * d[1:j] / n[1:j]))
        risk_table$c[j] = risk_table$C[j] + risk_table$w[j]
        
      }
  
      
    }
    else stop("unmatched method")
    
    # round w/c/C to 2dp
    
    risk_table$w = round(risk_table$w, 2)
    risk_table$c = round(risk_table$c, 2)
    risk_table$C = round(risk_table$C, 2)
    
    
    if (plot_weights){
      
      
      ltys = c("weights" = "solid",
               "score (censored)" = "dotted",
               "score (events)" = "dashed")
      
      p = ggplot(data = risk_table) +
        geom_line(aes(x = t, y = C, linetype = "score (censored)")) +
        geom_point(aes(x = t, y = C)) +
        geom_line(aes(x = t, y = c, linetype = "score (events)")) +
        geom_point(aes(x = t, y = c)) +
        geom_line(aes(x = t, y = w, linetype = "weights")) +
        geom_point(aes(x = t, y = w)) +
        scale_linetype_manual(name = "", 
                              values = ltys, 
                              limits = c("weights",
                                         "score (events)",
                                         "score (censored)"))
      
      return(list(risk_table = risk_table,
                  p = p))
      
    }
    else {
      
      risk_table
      
    }
    
  }

Package: modestWLRT
File: R/compare_weights.R
Format: text
Content:
  ############################################
  add_weights_list = function(weights_list, risk_table){
  
    if (weights_list$method == "fh"){
      weights_list$delay = NULL
    }
    else {
      weights_list$rho = NULL
      weights_list$gamma = NULL
    }
  
    add_weights(risk_table,
                method = weights_list$method,
                delay = weights_list$delay,
                rho = weights_list$rho,
                gamma = weights_list$gamma)
  
  }
  
  ###########################################
  #' Compare various methods to a simulated data set
  #'
  #' \code{compare_weights} will simulate a data set (according to \code{design})
  #' and will calculate standardized z-statistics for a variety of methods
  #' @param{weights_list_list} A list, where each element is a list describing a method. For example,
  #' \code{list(method="fixed_c",delay=6)} or \code{list(method="landmark", time = 20)}.
  #' @param{design} A list of design information, containing:
  #' \code{med_c}, \code{rate_e_1}, \code{rate_e_2}, \code{rec_period}, \code{rec_power}, \code{delay}, \code{max_cal_t}
  #' @return A vector of standardized test statistics, one for each method in \code{weights_list_list}.
  #' @export
  
  compare_weights = function(weights_list_list, design){
  
    which_landmark = unlist(lapply(weights_list_list,
                                   function(x) x$method == "landmark"))
    
    which_rmst = unlist(lapply(weights_list_list,
                               function(x) x$method == "rmst"))
    
    which_weights = !(which_landmark | which_rmst)
    
    real_weights = weights_list_list[which_weights]
    landmarks = weights_list_list[which_landmark]
    rmsts = weights_list_list[which_rmst]
  
    if (is.null(design$rate_c_1)){
      df = modestWLRT::delayed_effect_sim(n_c = design$n_c,
                                          n_e = design$n_e,
                                          med_c = design$med_c,
                                          rate_e_1 = design$rate_e_1,
                                          rate_e_2 = design$rate_e_2,
                                          rec_period = design$rec_period,
                                          rec_power = design$rec_power,
                                          delay = design$delay,
                                          max_cal_t = design$max_cal_t,
                                          n_events = design$n_events)
    }
    else {
      df = modestWLRT::three_piece_sim(n_c = design$n_c,
                                       n_e = design$n_e,
                                       rate_c_1 = design$rate_c_1,
                                       rate_c_2 = design$rate_c_2,
                                       rate_c_3 = design$rate_c_3,
                                       rate_e_1 = design$rate_e_1,
                                       rate_e_2 = design$rate_e_2,
                                       rate_e_3 = design$rate_e_3,
                                       rec_period = design$rec_period,
                                       rec_power = design$rec_power,
                                       delay_1 = design$delay_1,
                                       delay_2 = design$delay_2,
                                       max_cal_t = design$max_cal_t,
                                       n_events = design$n_events)
    }
  
    risk_table = get_risk_table(df)
    
    #####################
    ## weighted LRTs
    #####################
    if (length(real_weights) > 0){
    
      w_risk_table_list = lapply(real_weights,
                                 add_weights_list,
                                 risk_table = risk_table)
    
      w_z = lapply(w_risk_table_list, get_zs) %>%
              lapply(function(x)x[1]) %>%
              unlist()
  
    }
    else w_z = numeric(0)
    
    #####################
    ## landmarks
    #####################
    if (length(landmarks) > 0){
    
      land_times = unlist(lapply(landmarks, function(x)x$time))
      
      landmark_z = landmark(df = df,
                            time = land_times)
      
      names(landmark_z) = paste("landmark", land_times)
      
    }
    else landmark_z = numeric(0)
    
    #####################
    ## rmst
    #####################
    if (length(rmsts) > 0){
      
      rmst_times = lapply(rmsts, function(x)x$time)
      
      rmst_z = unlist(lapply(rmst_times, rmst, df = df))
        
      names(rmst_z) = paste("rmst", rmst_times)
      
    }
    else rmst_z = numeric(0)
    
    c(w_z, landmark_z, rmst_z)
  
  }

Package: modestWLRT
File: R/delayed_effect_sim.R
Format: text
Content:
  #' Simulate survival data from a two-arm trial
  #'
  #' \code{delayed_effect_sim} Simulate survival data: exponential vs. two-piece exponential.
  #' @param{n_c} Number of patients on control treatment.
  #' @param{n_e} Number of patients on experimental treatment.
  #' @param{rec_period} Recruitment period.
  #' @param{rec_power} Recruitment follows a power model. Pr(recruited before T) = (T / rec_period) ^ rec_power.
  #' @param{med_c} Median survival time on control.
  #' @param{rate_e_1} Event rate during first period on experimental arm.
  #' @param{rate_e_2} Event rate during second period on experimental arm.
  #' @param{delay} Length of first period.
  #' @param{max_cal_t} Maximum calendar time, i.e., time from start of the trial to data cut-off.
  #' @return A data frame containing survival time, whether patient has event (1 = yes, 0 = censored), and treatment arm.
  #' @export
  
  
  delayed_effect_sim = function(n_c = 100,
                                n_e = 100,
                                rec_period = 12,
                                rec_power = 1,
                                med_c = 15,
                                rate_e_1 = log(2) / 9,
                                rate_e_2 = 0.04,
                                delay = 6,
                                max_cal_t  = 36,
                                n_events = NULL){
  
    if (is.null(max_cal_t) && is.null(n_events)) stop("either max_cal_t or n_events must be specified.")
    if ((!is.null(max_cal_t)) && (!is.null(n_events))) stop("one of max_cal_t and n_events must be NULL.")
    if (is.null(max_cal_t) && (n_events > n_c + n_e)) stop("number of events not reached.")
    
    # simulate recruitment times from power model:
  
    rec_c = rec_period * runif(n_c) ^ (1 / rec_power)
    rec_e = rec_period * runif(n_e) ^ (1 / rec_power)
  
    # control event times are exponentially distributed:
  
    t_c = rexp(n_c, rate = log(2) / med_c)
  
    # experimental event times come from 2-piece exponential distribution:
  
    t_1_e = rexp(n_e, rate = rate_e_1)
    t_2_e = rexp(n_e, rate = rate_e_2)
    t_e = ifelse(t_1_e < delay, t_1_e, delay + t_2_e)
  
    # (calendar) event times, relative to start of trial.
  
    cal_t_c = rec_c + t_c
    cal_t_e = rec_e + t_e
  
    if (is.null(max_cal_t)){
      max_cal_t <- sort(c(cal_t_c, cal_t_e))[n_events]
    }
    
    # does the patient have an event before the data cut-off:
  
    event_c = cal_t_c <= max_cal_t
    event_e = cal_t_e <= max_cal_t
  
    # if patient's event time is censored, calculate their follow-up time:
  
    obs_t_c = ifelse(event_c, t_c, max_cal_t - rec_c)
    obs_t_e = ifelse(event_e, t_e, max_cal_t - rec_e)
  
    # store in data frame with group label:
  
    df = data.frame(time = c(obs_t_c, obs_t_e),
                    event = c(event_c, event_e),
                    group = rep(c("control", "experimental"), c(n_c, n_e)))
  
    # round time to 2 dp
    df$time = round(df$time, 2)
    
    df
  }
  

Package: modestWLRT
File: R/get_risk_table.R
Format: text
Content:
  #' Convert simulated survival data set into risk table format.
  #' 
  #' \code{get_risk_table} Calculate risk table for a simulated two-arm survival data set.
  #' @param{df} Data frame containing simulated survival data set in standard format. 
  #' Three columns: survival time \code{time}, whether patient has an \code{event} (1 = yes, 0 = censored), 
  #' and treatment \code{group" (\code{control" or \code{experimental}).
  #' @return A risk table with columns:
  #' \code{t} the event times, in ascending order
  #' \code{n_e} the number of patients at risk on the experimental treatment arm just prior to \code{t}.
  #' \code{n_c} the number of patients at risk on the control treatment arm just prior to \code{t}.
  #' \code{d_e} the number of events on the experimental arm at time \code{t}.
  #' \code{d_c} the number of events on the control arm at time \code{t}.
  #' \code{n} = \code{n_e} + \code{n_c}.
  #' \code{d} = \code{d_e} + \code{d_c}.
  #' \code{l} = \code{l_e} + \code{l_c}.
  #' \code{l_e} the number of patients on the experimental treatment arm who censored after the current \code{t} but before 
  #' the subsequent \code{t}.
  #' @export
  
  
  
  get_risk_table = function(df){
    
    # arrange the data set in increasing order of survival time:
    
    df = df[order(df$time),]
    
    # split into 2 data sets: one for control; one for experimental:
    
    df_c = df[df$group == "control",]
    df_e = df[df$group == "experimental",]
    
    # number of patients on each arm
    
    n_c = length(df_c$time)
    n_e = length(df_e$time)
    
    # the number of patients at risk will decrease by 1 after each event/censored observation.
    
    at_risk_c = n_c - 1:n_c + 1
    at_risk_e = n_e - 1:n_e + 1
    
    # create a risk table just for the control arm data...
    
    risk_table_c = data.frame(t = df_c$time,
                              n_c = at_risk_c,
                              d_c = as.numeric(df_c$event))
    
    # ...where there no patients/events on the experimental arm:
    
    risk_table_c$d_e = 0
    risk_table_c$n_e = NA
    
    # create a risk table just for the experimental arm data...
    
    risk_table_e = data.frame(t = df_e$time,
                              n_e = at_risk_e,
                              d_e = as.numeric(df_e$event))
    
    # ...where there are no patients/events on the control arm:
    
    risk_table_e$d_c = 0
    risk_table_e$n_c = NA
    
    # put the risk tables on top of each other...
    
    risk_table = rbind(risk_table_c, risk_table_e)
    
    # ...and reorder by event/censoring times (across both arms):
    
    risk_table = risk_table[order(risk_table$t),]
    
    # whenever is.na(n_e) == TRUE, this means that the event/censored observation on this 
    # row was from the control arm. To fill in the number at risk on the experimental
    # arm we look at the subsequent row, repeating if necessary, until we find a row
    # where is.na(n_e) == FALSE.
    # similarly for n_c when is.na(n_c) == TRUE.
    
    risk_table = risk_table %>% tidyr::fill(n_e, n_c, .direction = "up")
    
    # at the bottom of the risk table, it's still possible that is.na(n_e) == TRUE if
    # all subsequent events/censorings are from the control arm. In this case the 
    # number at risk is zero. Similarly for the control arm.
    
    risk_table$n_c[is.na(risk_table$n_c)] = 0
    risk_table$n_e[is.na(risk_table$n_e)] = 0
    
    # now we deal with ties. We group together the data that have the same value of "t",
    # work out how many patients were at risk just prior to "t", and how many events
    # happened at "t":
    
    risk_table = risk_table %>% 
      group_by(t) %>%
      summarize(n_e = max(n_e),
                d_e = sum(d_e),
                n_c = max(n_c),
                d_c = sum(d_c)) %>%
      as.data.frame()
    
    # we only keep the "t" where there was at least one event:
    
    risk_table = risk_table[risk_table$d_e > 0 | risk_table$d_c > 0,]
    
    # calculate number of events, number at risk across arms.
    
    risk_table$n = risk_table$n_e + risk_table$n_c
    risk_table$d = risk_table$d_e + risk_table$d_c
    
    # calculate the number censored between consecutive event times:
    
    risk_table$l = risk_table$n - risk_table$d - c(risk_table$n[-1], 0)
    risk_table$l_c = risk_table$n_c - risk_table$d_c - c(risk_table$n_c[-1], 0)
    risk_table$l_e = risk_table$n_e - risk_table$d_e - c(risk_table$n_e[-1], 0)
    
    # return the completed risk table:
    
    risk_table
    
  }

Package: modestWLRT
File: R/get_zs.R
Format: text
Content:
  #' Get (standardized) score and weighted log-rank statistics.
  #' 
  #' \code{get_zs} Calculate (standardized) score and weighted log-rank statistics from risk table (with weights).
  #' @param{risk_table} A risk table with weights produced by the functions \code{get_risk_table} and \code{add_weights}.
  #' @param{method} If \code{method = "u"} then the logrank formula is used. If \code{method = "s"} then the score test formula is used.
  #' @return The standardized weighted log-rank statistic.
  #' @export
  #' 
  #' 
  get_zs = function(risk_table, method = "u"){
    
    if (class(risk_table) == "list") risk_table = risk_table$risk_table
    
    n_e = max(risk_table$n_e)
    n_c = max(risk_table$n_c)
    
    # formulas for S and V[S] in Leton and Zuluaga pg. 595.
    
    s = with(risk_table, sum(d_c * c + l_c * C))
    v_s = with(risk_table, sum(d * c ^ 2 + l * C ^ 2)) * n_c * n_e / (n_c + n_e) / (n_c + n_e - 1)
    
    z_s = s / sqrt(v_s)
    
    # formulas for U and V[U] in Leton and Zuluaga pg. 596.
    
    u = with(risk_table, sum(w * (d_c - d * n_c / n)))
    v_u = with(risk_table, sum(w^2 * n_c * n_e * d * (n - d) / n / n / (n - 1), na.rm = TRUE))
    
    z_u = u / sqrt(v_u)
  
    if (method == "u") return(z_u)
    if (method == "s") return(z_s)
    c(z_u = z_u,
      z_s = z_s)
    
    
  }

Package: modestWLRT
File: R/landmark.R
Format: text
Content:
  #' Perform a landmark analysis at a specified (patient) time.
  #' 
  #' \code{landmark} performs a landmark analysis at a specified (patient) time. Based on Kaplan-Meier estimates of survival 
  #' on the two treatment arms.
  #' @param{df} Data frame containing simulated survival data set in standard format. 
  #' Three columns: survival time \code{time}, whether patient has an \code{event} (1 = yes, 0 = censored), 
  #' and treatment \code{group" (\code{control" or \code{experimental}).
  #' @param{time} The (patient) times to perform the landmark analysis at. E.g., survival at \code{time = c(6,12,18)} months.
  #' @return \code{z} the standardized test statistic. Large values indicate better survival on the experimental arm.
  #' @export
  
  
  
  landmark = function(df, time){
  
    ## use survival::survfit to do KM estimation by group:
    fit <- survival::survfit(Surv(time, event) ~ group, data = df)
    
    no_data <- min(fit$time[fit$n.risk == 1]) < time
    time <- time[!no_data]
    #if(any(min(fit$time[fit$n.risk == 1]) < time)) return(rep(NA, length(time)))
    
    info = summary(fit, time = time)
    
    
    ## extract survival probabilities with standard errors:
    
    info_df = data.frame(t = info$time,
                         p = info$surv,
                         se = info$std.err,
                         group = info$strata)
    
    
    
    z_stats = info_df %>% 
                group_by(t) %>%
                summarize(diff = p[group == "group=experimental"] - p[group == "group=control"],
                          se = sqrt(sum(se ^ 2))) %>%
                mutate(z = diff/se)
  
    c(z_stats$z, rep(NA, sum(no_data)))
    
  }
  
  

Package: modestWLRT
File: R/ncp_power.R
Format: text
Content:
  ############### model extend #######################
  
  model_extend <- function(model,
                           max_t,
                           length_t){
    
    change_points_plus <- unique(sort(c(seq(0, 
                                            max_t, 
                                            length.out = length_t), 
                                        model$change_points)))
    
    which_lambda <- purrr::map_dbl(change_points_plus, 
                                   function(x) sum(x >= model$change_points)) + 1
    
    
    list(change_points = change_points_plus[-1],
         lambdas_0 = model$lambdas_0[which_lambda],
         lambdas_1 = model$lambdas_1[which_lambda])
    
    
  }
  
  
  ########## \bar{S} ############
  
  s_bar <- function(t, recruitment, model){
    
    a_0 <- recruitment$n_0 / (recruitment$n_0 + recruitment$n_1)
    a_1 <- 1 - a_0
    
    s_0 <- expectedevents:::surv_pieces_simple(t, model$change_points, model$lambdas_0)
    s_1 <- expectedevents:::surv_pieces_simple(t, model$change_points, model$lambdas_1)
    
    a_0 * s_0 + a_1 * s_1
    
  }
  
  ########## w ##################
  
  w <- function(t, t_star, recruitment, model){
    
    s_bar(pmin(t, t_star), recruitment, model) ^ (-1)
    
  }
  
  
  ######### ncp ############
  
  #' Find the approximate non-centrality parameter and power of a modestWLRT.
  #' 
  #' \code{ncp_power} returns the approximate non-centrality parameter and power of a modestWLRT for a range
  #' of possible values of t*.
  #' @param{t_star} A vector. A range of possible values for t*.
  #' @param{model} A piecewise constant hazard model.
  #'   A list containing the \code{change_points}; the rates \code{lambdas_0} on the control arm; 
  #'   and the rates \code{lambdas_1} on the treatment arm.
  #' @param{recruitment} List of recruitment information. 
  #'   Containing \enumerate{
  #'                 \item Sample size on control, \code{n_0} 
  #'                 \item Sample size on treatment, \code{n_1} 
  #'                 \item Recruitment period, \code{r_period}
  #'                 \item Recruitment parameter for power model, \code{k} 
  #'               }
  #' @param{dco} Time of data cut-off. 
  #' @param{length_t}  
  #' @param{alpha_one_sided} 
  #' @return A list containing
  #' \enumerate{
  #'                 \item non-centrality parameter corresponding to each t* \code{ncp} 
  #'                 \item power corresponding to each t* \code{power}
  #'           }
  #' @export
  
  
  ncp_power <- function(t_star, 
                        model,
                        recruitment,
                        dco,
                        length_t,
                        alpha_one_sided = 0.025){
    
    R <- recruitment$n_1 / recruitment$n_0
    
    model_e <- model_extend(model, max_t = dco, length_t = length_t)
    
    events_info <- expectedevents::expected_events_two_arm(dco = dco,
                                                           recruitment = recruitment,
                                                           model = model_e,
                                                           mu = 0, 
                                                           total_only = FALSE)
    
    prop_events <- events_info$prop_events
    total_events <- events_info$total_events
    
    mid_t <- c(0, model_e$change_points[-length(model_e$change_points)]) + diff(c(0, model_e$change_points)) / 2
    
    ncp <- numeric(length(t_star))
    power <- numeric(length(t_star))
    var_u <- numeric(length(t_star))
    e_u <- numeric(length(t_star))
    
    for (i in seq_along(ncp)){
      
      weights_t_star <- purrr::map_dbl(mid_t,
                                       w,
                                       t_star = t_star[i],
                                       recruitment = recruitment,
                                       model = model_e)
      
  
      weights_t_star <- c(weights_t_star, 0)
      
      log_hr <- log(model_e$lambdas_1 / model_e$lambdas_0)
      
      
      num <- sum(weights_t_star * log_hr * prop_events)
      denom <- sqrt(sum(weights_t_star ^ 2 * prop_events))
      
      ncp[i] <- num / denom * sqrt(total_events * R / (R + 1) ^ 2)
      power[i] <- pnorm(qnorm(alpha_one_sided),
                        mean = num / denom * sqrt(total_events * R / (R + 1) ^ 2))
      
      e_u[i] <- sum(weights_t_star * log_hr * prop_events * total_events * R / (R + 1) ^ 2)
      var_u[i] <- sum(weights_t_star ^ 2 * prop_events * total_events * R / (R + 1) ^ 2)
      
    }
    list(ncp = ncp,
         power = power,
         e_u = e_u,
         var_u = var_u,
         total_events = total_events)
  }
  
  
  

Package: modestWLRT
File: R/rmst.R
Format: text
Content:
  #' Perform a restricted-mean survival time.
  #' 
  #' \code{rmst} performs a restricted mean survival time analysis at a specified (patient) time.
  #' @param{df} Data frame containing simulated survival data set in standard format. 
  #' Three columns: survival time \code{time}, whether patient has an \code{event} (1 = yes, 0 = censored), 
  #' and treatment \code{group" (\code{control" or \code{experimental}).
  #' @param{time} The (patient) time to perform the RMST analysis at. Must be length 1.
  #' @return \code{z} the standardized test statistic. Large values indicate better survival on the experimental arm.
  #' @export
  
  
  
  rmst = function(df, time){
    
    if (length(time) != 1) stop("time must be length 1")
    
    ## use survival::survfit to do KM estimation by group:
    fit <- survival::survfit(Surv(time, event) ~ group, data = df)
    
    if(any(min(fit$time[fit$n.risk == 1]) < time)) {
      
      return(NA)
      
    }
    else {
      ## use survRM2:: to do RMST estimation by group:
      results <- rmst2(time = df$time, 
                       status = as.numeric(df$event), 
                       arm = ifelse(df$group == "control", 0, 1),
                       tau = time)
    }
    
    mean_1 <- results$RMST.arm1$rmst["Est."]
    se_1 <- results$RMST.arm1$rmst["se"]
    
    mean_0 <- results$RMST.arm0$rmst["Est."]
    se_0 <- results$RMST.arm0$rmst["se"]
    
    mean_diff <- mean_1 - mean_0
    se_diff <- sqrt(se_0 ^ 2 + se_1 ^2)
    
    z_diff <- mean_diff / se_diff
    
    z_diff
    
    
  }
  
  

Package: modestWLRT
File: R/three_piece_sim.R
Format: text
Content:
  #' Simulate survival data from a two-arm trial
  #'
  #' \code{three_piece_sim} Simulate survival data: three-piece exponential vs. three-piece exponential.
  #' @param{n_c} Number of patients on control treatment.
  #' @param{n_e} Number of patients on experimental treatment.
  #' @param{rec_period} Recruitment period.
  #' @param{rec_power} Recruitment follows a power model. Pr(recruited before T) = (T / rec_period) ^ rec_power.
  #' @param{rate_c_1} Event rate during first period on control arm.
  #' @param{rate_c_2} Event rate during second period on control arm.
  #' @param{rate_c_3} Event rate during third period on control arm.
  #' @param{rate_e_1} Event rate during first period on experimental arm.
  #' @param{rate_e_2} Event rate during second period on experimental arm.
  #' @param{rate_e_3} Event rate during third period on experimental arm.
  #' @param{delay_1} Time of first change point.
  #' @param{delay_2} Time of second change point.
  #' @param{max_cal_t} Maximum calendar time, i.e., time from start of the trial to data cut-off.
  #' @return A data frame containing survival time, whether patient has event (1 = yes, 0 = censored), and treatment arm.
  #' @export
  
  
  three_piece_sim = function(n_c = 100,
                             n_e = 100,
                             rec_period = 12,
                             rec_power = 1,
                             rate_c_1 = log(2) / 9,
                             rate_c_2 = 0.04,
                             rate_c_3 = 0.04,
                             rate_e_1 = log(2) / 9,
                             rate_e_2 = 0.04,
                             rate_e_3 = 0.04,
                             delay_1 = 6,
                             delay_2 = 12,
                             max_cal_t  = 36,
                             n_events = NULL){
    
    if (is.null(max_cal_t) && is.null(n_events)) stop("either max_cal_t or n_events must be specified.")
    if ((!is.null(max_cal_t)) && (!is.null(n_events))) stop("one of max_cal_t and n_events must be NULL.")
    if (is.null(max_cal_t) && (n_events > n_c + n_e)) stop("number of events not reached.")
    
    # simulate recruitment times from power model:
    
    rec_c = rec_period * runif(n_c) ^ (1 / rec_power)
    rec_e = rec_period * runif(n_e) ^ (1 / rec_power)
    
    # control event times are 3-piece exponentially distributed:
    t_1_c = rexp(n_c, rate = rate_c_1)
    t_2_c = rexp(n_c, rate = rate_c_2)
    t_3_c = rexp(n_c, rate = rate_c_3)
    t_c = ifelse(t_1_c < delay_1,
                 t_1_c,
                 ifelse(delay_1 + t_2_c < delay_2, delay_1 + t_2_c, delay_2 + t_3_c)) 
    
    # experimental event times come from 3-piece exponential distribution:
    
    t_1_e = rexp(n_e, rate = rate_e_1)
    t_2_e = rexp(n_e, rate = rate_e_2)
    t_3_e = rexp(n_e, rate = rate_e_3)
    t_e = ifelse(t_1_e < delay_1,
                 t_1_e,
                 ifelse(delay_1 + t_2_e < delay_2, delay_1 + t_2_e, delay_2 + t_3_e)) 
    
    # (calendar) event times, relative to start of trial.
    
    cal_t_c = rec_c + t_c
    cal_t_e = rec_e + t_e
    
    if (is.null(max_cal_t)){
      max_cal_t <- sort(c(cal_t_c, cal_t_e))[n_events]
    }
    
    # does the patient have an event before the data cut-off:
    
    event_c = cal_t_c <= max_cal_t
    event_e = cal_t_e <= max_cal_t
    
    # if patient's event time is censored, calculate their follow-up time:
    
    obs_t_c = ifelse(event_c, t_c, max_cal_t - rec_c)
    obs_t_e = ifelse(event_e, t_e, max_cal_t - rec_e)
    
    # store in data frame with group label:
    
    df = data.frame(time = c(obs_t_c, obs_t_e),
                    event = c(event_c, event_e),
                    group = rep(c("control", "experimental"), c(n_c, n_e)),
                    rec = c(rec_c, rec_e))
    
    # round time to 2 dp
    df$time = round(df$time, 2)
    
    df$max_cal_t = max_cal_t
    
    df
  }

Package: modestWLRT
File: man/add_weights.Rd
Format: text
Content:
  % Generated by roxygen2: do not edit by hand
  % Please edit documentation in R/add_weights.R
  \name{add_weights}
  \alias{add_weights}
  \title{Calculate weights for a weighted log-rank test.}
  \usage{
  add_weights(risk_table, method = "fixed_c", delay = 6, rho = 0,
    gamma = 0, plot_weights = FALSE)
  }
  \arguments{
  \item{{risk_table}}{A risk table produced by the function \code{get_risk_table}.}
  
  \item{{method}}{The type of weighted log-rank test.
  \code{"fixed_c"} means that the scores \code{c} are fixed at 1 while \code{t < delay}. Thereafter, the weights \code{w} remain fixed.
  \code{"fh"} is a Fleming-Harrington test with parameters \code{rho} and \code{gamma}.
  \code{"step"} means that the weight \code{w} is fixed at 0 while \code{t < delay}. Thereafter, the weight is fixed at 1.}
  
  \item{{delay}}{Parameter used by the \code{"fixed_c"} and \code{"step"} methods.}
  
  \item{{rho}}{First parameter for the \code{"fh"} method.}
  
  \item{{gamma}}{Second parameter for the \code{"fh"} method.}
  }
  \value{
  A risk table consisting of the original \code{risk_table} with 3 additional columns:
  \code{c} The scores in the score test corresponding to events (uncensored observations).
  \code{w} The weights for the weighted log-rank test. 
  \code{C} The scores in the score test corresponding to censored observations.
  }
  \description{
  \code{add_weights} Calculate weights for a weighted log-rank test and add them to the risk table.
  }

Package: modestWLRT
File: man/compare_weights.Rd
Format: text
Content:
  % Generated by roxygen2: do not edit by hand
  % Please edit documentation in R/compare_weights.R
  \name{compare_weights}
  \alias{compare_weights}
  \title{Compare various methods to a simulated data set}
  \usage{
  compare_weights(weights_list_list, design)
  }
  \arguments{
  \item{{weights_list_list}}{A list, where each element is a list describing a method. For example,
  \code{list(method="fixed_c",delay=6)} or \code{list(method="landmark", time = 20)}.}
  
  \item{{design}}{A list of design information, containing:
  \code{med_c}, \code{rate_e_1}, \code{rate_e_2}, \code{rec_period}, \code{rec_power}, \code{delay}, \code{max_cal_t}}
  }
  \value{
  A vector of standardized test statistics, one for each method in \code{weights_list_list}.
  }
  \description{
  \code{compare_weights} will simulate a data set (according to \code{design})
  and will calculate standardized z-statistics for a variety of methods
  }

Package: modestWLRT
File: man/delayed_effect_sim.Rd
Format: text
Content:
  % Generated by roxygen2: do not edit by hand
  % Please edit documentation in R/delayed_effect_sim.R
  \name{delayed_effect_sim}
  \alias{delayed_effect_sim}
  \title{Simulate survival data from a two-arm trial}
  \usage{
  delayed_effect_sim(n_c = 100, n_e = 100, rec_period = 12,
    rec_power = 1, med_c = 15, rate_e_1 = log(2)/9, rate_e_2 = 0.04,
    delay = 6, max_cal_t = 36, n_events = NULL)
  }
  \arguments{
  \item{{n_c}}{Number of patients on control treatment.}
  
  \item{{n_e}}{Number of patients on experimental treatment.}
  
  \item{{rec_period}}{Recruitment period.}
  
  \item{{rec_power}}{Recruitment follows a power model. Pr(recruited before T) = (T / rec_period) ^ rec_power.}
  
  \item{{med_c}}{Median survival time on control.}
  
  \item{{rate_e_1}}{Event rate during first period on experimental arm.}
  
  \item{{rate_e_2}}{Event rate during second period on experimental arm.}
  
  \item{{delay}}{Length of first period.}
  
  \item{{max_cal_t}}{Maximum calendar time, i.e., time from start of the trial to data cut-off.}
  }
  \value{
  A data frame containing survival time, whether patient has event (1 = yes, 0 = censored), and treatment arm.
  }
  \description{
  \code{delayed_effect_sim} Simulate survival data: exponential vs. two-piece exponential.
  }

Package: modestWLRT
File: man/get_risk_table.Rd
Format: text
Content:
  % Generated by roxygen2: do not edit by hand
  % Please edit documentation in R/get_risk_table.R
  \name{get_risk_table}
  \alias{get_risk_table}
  \title{Convert simulated survival data set into risk table format.}
  \usage{
  get_risk_table(df)
  }
  \value{
  A risk table with columns:
  \code{t} the event times, in ascending order
  \code{n_e} the number of patients at risk on the experimental treatment arm just prior to \code{t}.
  \code{n_c} the number of patients at risk on the control treatment arm just prior to \code{t}.
  \code{d_e} the number of events on the experimental arm at time \code{t}.
  \code{d_c} the number of events on the control arm at time \code{t}.
  \code{n} = \code{n_e} + \code{n_c}.
  \code{d} = \code{d_e} + \code{d_c}.
  \code{l} = \code{l_e} + \code{l_c}.
  \code{l_e} the number of patients on the experimental treatment arm who censored after the current \code{t} but before 
  the subsequent \code{t}.
  }
  \description{
  \code{get_risk_table} Calculate risk table for a simulated two-arm survival data set.
  }

Package: modestWLRT
File: man/get_zs.Rd
Format: text
Content:
  % Generated by roxygen2: do not edit by hand
  % Please edit documentation in R/get_zs.R
  \name{get_zs}
  \alias{get_zs}
  \title{Get (standardized) score and weighted log-rank statistics.}
  \usage{
  get_zs(risk_table, method = "u")
  }
  \arguments{
  \item{{risk_table}}{A risk table with weights produced by the functions \code{get_risk_table} and \code{add_weights}.}
  
  \item{{method}}{If \code{method = "u"} then the logrank formula is used. If \code{method = "s"} then the score test formula is used.}
  }
  \value{
  The standardized weighted log-rank statistic.
  }
  \description{
  \code{get_zs} Calculate (standardized) score and weighted log-rank statistics from risk table (with weights).
  }

Package: modestWLRT
File: man/landmark.Rd
Format: text
Content:
  % Generated by roxygen2: do not edit by hand
  % Please edit documentation in R/landmark.R
  \name{landmark}
  \alias{landmark}
  \title{Perform a landmark analysis at a specified (patient) time.}
  \usage{
  landmark(df, time)
  }
  \arguments{
  \item{{time}}{The (patient) times to perform the landmark analysis at. E.g., survival at \code{time = c(6,12,18)} months.}
  }
  \value{
  \code{z} the standardized test statistic. Large values indicate better survival on the experimental arm.
  }
  \description{
  \code{landmark} performs a landmark analysis at a specified (patient) time. Based on Kaplan-Meier estimates of survival 
  on the two treatment arms.
  }

Package: modestWLRT
File: man/ncp_power.Rd
Format: text
Content:
  % Generated by roxygen2: do not edit by hand
  % Please edit documentation in R/ncp_power.R
  \name{ncp_power}
  \alias{ncp_power}
  \title{Find the approximate non-centrality parameter and power of a modestWLRT.}
  \usage{
  ncp_power(t_star, model, recruitment, dco, length_t,
    alpha_one_sided = 0.025)
  }
  \arguments{
  \item{{t_star}}{A vector. A range of possible values for t*.}
  
  \item{{model}}{A piecewise constant hazard model.
  A list containing the \code{change_points}; the rates \code{lambdas_0} on the control arm; 
  and the rates \code{lambdas_1} on the treatment arm.}
  
  \item{{recruitment}}{List of recruitment information. 
  Containing \enumerate{
                \item Sample size on control, \code{n_0} 
                \item Sample size on treatment, \code{n_1} 
                \item Recruitment period, \code{r_period}
                \item Recruitment parameter for power model, \code{k} 
              }}
  
  \item{{dco}}{Time of data cut-off.}
  
  \item{{length_t}}{}
  
  \item{{alpha_one_sided}}{}
  }
  \value{
  A list containing
  \enumerate{
                  \item non-centrality parameter corresponding to each t* \code{ncp} 
                  \item power corresponding to each t* \code{power}
            }
  }
  \description{
  \code{ncp_power} returns the approximate non-centrality parameter and power of a modestWLRT for a range
  of possible values of t*.
  }

Package: modestWLRT
File: man/rmst.Rd
Format: text
Content:
  % Generated by roxygen2: do not edit by hand
  % Please edit documentation in R/rmst.R
  \name{rmst}
  \alias{rmst}
  \title{Perform a restricted-mean survival time.}
  \usage{
  rmst(df, time)
  }
  \arguments{
  \item{{time}}{The (patient) time to perform the RMST analysis at. Must be length 1.}
  }
  \value{
  \code{z} the standardized test statistic. Large values indicate better survival on the experimental arm.
  }
  \description{
  \code{rmst} performs a restricted mean survival time analysis at a specified (patient) time.
  }

Package: modestWLRT
File: man/three_piece_sim.Rd
Format: text
Content:
  % Generated by roxygen2: do not edit by hand
  % Please edit documentation in R/three_piece_sim.R
  \name{three_piece_sim}
  \alias{three_piece_sim}
  \title{Simulate survival data from a two-arm trial}
  \usage{
  three_piece_sim(n_c = 100, n_e = 100, rec_period = 12,
    rec_power = 1, rate_c_1 = log(2)/9, rate_c_2 = 0.04,
    rate_c_3 = 0.04, rate_e_1 = log(2)/9, rate_e_2 = 0.04,
    rate_e_3 = 0.04, delay_1 = 6, delay_2 = 12, max_cal_t = 36,
    n_events = NULL)
  }
  \arguments{
  \item{{n_c}}{Number of patients on control treatment.}
  
  \item{{n_e}}{Number of patients on experimental treatment.}
  
  \item{{rec_period}}{Recruitment period.}
  
  \item{{rec_power}}{Recruitment follows a power model. Pr(recruited before T) = (T / rec_period) ^ rec_power.}
  
  \item{{rate_c_1}}{Event rate during first period on control arm.}
  
  \item{{rate_c_2}}{Event rate during second period on control arm.}
  
  \item{{rate_c_3}}{Event rate during third period on control arm.}
  
  \item{{rate_e_1}}{Event rate during first period on experimental arm.}
  
  \item{{rate_e_2}}{Event rate during second period on experimental arm.}
  
  \item{{rate_e_3}}{Event rate during third period on experimental arm.}
  
  \item{{delay_1}}{Time of first change point.}
  
  \item{{delay_2}}{Time of second change point.}
  
  \item{{max_cal_t}}{Maximum calendar time, i.e., time from start of the trial to data cut-off.}
  }
  \value{
  A data frame containing survival time, whether patient has event (1 = yes, 0 = censored), and treatment arm.
  }
  \description{
  \code{three_piece_sim} Simulate survival data: three-piece exponential vs. three-piece exponential.
  }

Package: modestWLRT
File: vignettes/modestwlrt_vignette.Rmd
Format: text
Content:
  ---
  title: "Modestly-weighted logrank test: basic tutorial"
  author: "Dominic Magirr"
  date: "`r Sys.Date()`"
  output: 
    pdf_document:
          fig_caption: yes
  vignette: >
    %\VignetteIndexEntry{Basic tutorial}
    %\VignetteEngine{knitr::rmarkdown}
    %\VignetteEncoding{UTF-8}
  ---
  
  ```{r setup, include = FALSE}
  knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>"
  )
  ```
  
  # Installation
  
  You can use `devtools::install_github()` to get the package from [GitHub](https://github.com/dominicmagirr/modestWLRT):
  
  ```{r eval=FALSE}
  install.packages("devtools")
  library(devtools)
  install_github("dominicmagirr/expectedevents")
  install_github("dominicmagirr/modestWLRT")
  ```
  
  
  # Load packages
  
  ```
  library(dplyr)
  library(ggplot2)
  library(expectedevents)
  library(modestWLRT)
  ```
  
  ```{r include=FALSE}
  library(dplyr)
  library(ggplot2)
  devtools::load_all("..")
  devtools::load_all("~/AAC/tools/expectedevents")
  ```
  
  # Perform a mWLRT
  
  ## Simulate example data set
  
  You can use the function `delayed_effect_sim` to simulate an example data set from a 2-arm RCT. Survival times on the control arm are exponentially distributed with median `med_c`. Survival times on the experimental arm follow a 2-piece exponential distibution: from time zero up to time `delay` the event rate is `rate_e_1`; thereafter the event rate is `rate_e_2`. Patient recruitment times follow a simple power distribution:
  
  pr(recruited before t) = (t / `rec_period`)^`rec_power`, for t in (0, `rec_period`).
  
  Data cut-off happens at time `max_cal_t`, and any patients still alive have their survival time censored.
  
  ```{r}
  set.seed(459)
  example_data = delayed_effect_sim(n_c = 10,
                                    n_e = 10,
                                    rec_period = 12,
                                    rec_power = 1,
                                    med_c = 15,
                                    rate_e_1 = log(2) / 15,
                                    rate_e_2 = 0.03,
                                    delay = 6,
                                    max_cal_t  = 36)
  
  example_data
  ```
  
  
  ## Risk table
  
  The function `get_risk_table` takes a data frame produced from `delayed_effect_sim` (or a data frame of the same form) and turns it into a risk table. This tells you how many patients were at risk / had an event / censored on each arm, at each event time.
  
  ```{r}
  example_risk_table = get_risk_table(example_data)
  
  example_risk_table
  ```
  
  ## Calculate weights
  
  From the risk table, you can calculate the scores / weights from a modestWLRT. The argument `delay` is used to specify how long the scores are kept constant. See the paper
  
  http://arxiv.org/abs/1807.11097
  
  for details.
  
  ```{r}
  modest_weights = add_weights(example_risk_table, 
                               method = "fixed_c", 
                               delay = 12, 
                               plot_weights = TRUE)
  ```
  
  ```{r}
  modest_weights$risk_table
  ```
  
  ```{r fig.cap = "Scores/weights from a modestWLRT."}
  modest_weights$p
  ```
  
  ## Test statistics
  
  Given the risk table with the corresponding weights, it is simple to calculate the standardized weighted logrank statistic. Larger values of Z correspond to longer survival times on the experimental arm.
  
  ```{r}
  get_zs(modest_weights)
  ```
  
  
  # Approximate non-centrality parameter / power
  
  To approximate the non-centrality parameter (and therefore power) of a mWLRT, we split the test statistic up into smaller chunks:
  
  $$U = \sum_{k=0}^{\infty} U_k$$
  
  where, for some time interval $t'$,
  
  $$ U_k = \sum_{j:~t_j \in (kt', kt'+t')} ~~w_j\left( d_{0,j} - d_j\frac{n_{0,j}}{n_j}\right).$$
  
  Let $e_k$ and $\theta_k$ denote the number of events and log-hazard ratio, respectively, during the time interval $(kt', kt' + t')$. Approximately, for large $e_k$ and small $\theta_k$,
  
  $$ U_k \sim N(\tilde{w}_k \theta_k I_k, ~\tilde{w}_k^2 I_k), $$
  where $I_k = e_k R / (R+1)^2$ for $R:1$ allocation, and $\tilde{w}_k$ denotes an "average" weight during $(kt', kt' + t')$.
  
  
  When designing the study we make assumptions about survival distributions on each arm, as well as the recruitment distribution. We can use this to calculate 
  
  $$\tilde{w}_k = 1 / S^* \left(\min\left\lbrace kt' + 0.5t', t^* \right\rbrace \right),$$
  where $S^*$ denotes the assumed survival distribution for the pooled sample. We also use numerical integration to find
  
  $$E(e_k) = N \times \pi_k$$
  
  where $\pi_k$ denotes the probability of a randomly chosen patient having an event during $(kt', kt' + t')$. 
  
  Putting these pieces together, the standardized logrank statistic $U / \text{var} (U)$ is approximately normally distribution with non-centrality parameter
  
  $$ \sqrt{N} \times \frac{\sum_k \tilde{w}_k \theta_k \pi_k}{\left( \sum_k  \tilde{w}_k^2 \pi_k \right)^{1/2}}.$$
  
  To do this in the `modestWLRT` package, we first specify recruitment assumptions. We assume that
  
  $$ pr(\text{recruited prior to time }r) = (r / R)^k $$
  where $R$ denotes the length of the recruitment period.
  
  
  ```{r}
  recruitment_1 = list(n_0 = 100, 
                       n_1 = 100, 
                       r_period = 12, 
                       k = 1)
  
  ```
  
  
  Next we specify the survival distributions on the two arms. This is done via piece-wise constant hazards. In this simple example, there are only two pieces. During period 1 (0 -- 6 months), the hazard rate is the same on both arms. During period 2 (6 months onwards), the hazard ratio is 0.5.
  
  
  ```{r}
  model_1 = list(change_points = 6, 
                 lambdas_0 = c(log(2) / 15, log(2) / 15), 
                 lambdas_1 = c(log(2) / 15, log(2) / 30))
  
  ```
  
  
  We want to evaluate the ncp/power for a sequence of pontential values for $t^*$.
  
  ```{r}
  t_star_seq <- seq(2,36,2)
  ```
  
  
  Finally, when calling `ncp_power`, we must also specify the calendar time of data cut-off (`dco`) and the number of pieces to split the log-rank test into (`length_t`). The larger `length_t`, the smaller $t'$.
  
  ```{r}
  results <- ncp_power(t_star = t_star_seq, 
                       model = model_1,
                       recruitment = recruitment_1,
                       dco = 36,
                       length_t = 50)
  
  ```
  
  The output is the approximate non-centrality parameter for each value of $t^*$...
  
  ```{r}
  plot(t_star_seq, results$ncp, type = 'b')
  ```
  
  ...and corresponding power (by default for one-sided type 1 error rate of 2.5%):
  
  ```{r}
  plot(t_star_seq, results$power, type = 'b')
  ```
  
  
  
  In this case, the best choice of $t^*$ is about 22 months.
  
  
  
  
  
  
  
  
  

